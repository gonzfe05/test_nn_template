{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook hypotheses\n",
    "#### 1. Contrastative learning embedding has significantly better separability than PCA or tsne even when overfitted\n",
    "\n",
    "### Motivation\n",
    "Compare contrastative learning model against benchmarks that should perform worse.\n",
    "* PCA is a simple and fast linear method, shouldnt beat a contrastative model non-linear mapping in a complex problems.\n",
    "* t-sne does not learn a mapping from feature-space so cant be used as an embedding. If we cant beat t-sne then there is a better non-linear mapping we have not achived. \n",
    "\n",
    "### Actions:\n",
    "* Hypotheses N. 1 is `True`.\n",
    "    * Make a dataset of embeddings useful for training a classifier\n",
    "* Hypotheses N. 1 is `False`.\n",
    "    * Review contrastative learning model.\n",
    "\n",
    "### Results:\n",
    "* 1. `True`, contrastative embedding has orders of magnitude more separability. [Link](#techniques-separability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb metadata\n",
    "NB_NAME = \"dimentionality reduction.ipynb\"\n",
    "NB_PATH = \"notebooks\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrastative embeddings dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env WANDB_API_KEY=4f8699d18b665419da19c00aeb7291bcafb88ac5\n",
    "# import os\n",
    "# os.environ['WANDB_API_KEY'] = '4f8699d18b665419da19c00aeb7291bcafb88ac5'\n",
    "from omegaconf import DictConfig\n",
    "from test_nn_template.run import WandbHandler\n",
    "\n",
    "print(f\"Runs: {len(WandbHandler.get_runs(entity='fernandoezequiel512', project='test_nn_template'))}\")\n",
    "run_id = \"fernandoezequiel512/test_nn_template/runs/28vaq6y9\"\n",
    "run = WandbHandler.get_run(run_id)\n",
    "print(f\"Got {run.name}\")\n",
    "model = WandbHandler.load_run_model_checkpoint(run_id)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def replace_dataset(cfg: DictConfig):\n",
    "    _target_train = cfg.data.datamodule.datasets.train._target_.replace(\"MyContrastativeDataset\", \"MyDataset\")\n",
    "    _target_test = cfg.data.datamodule.datasets.test._target_.replace(\"MyContrastativeDataset\", \"MyDataset\")\n",
    "    cfg.data.datamodule.datasets.train._target_ = _target_train\n",
    "    cfg.data.datamodule.datasets.test._target_ = _target_test\n",
    "    return cfg\n",
    "\n",
    "\n",
    "datamodule = WandbHandler.load_run_datamodule(run_id, cfg_func=replace_dataset)\n",
    "# print(datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup(stage=\"test\")\n",
    "test_dataloader = datamodule.test_dataloader()[0]\n",
    "train_dataloader = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from test_nn_template.data.datamodule import MyDataModule\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "x_contrast = []\n",
    "labels = []\n",
    "for x, y in test_dataloader:\n",
    "    # print(x.shape, y.detach().numpy())\n",
    "    emb = model.model.forward_once(x).detach().numpy()\n",
    "    x_contrast.append(emb)\n",
    "    labels.append(y)\n",
    "    # break\n",
    "x_contrast = np.concatenate(x_contrast)\n",
    "labels = np.concatenate(labels)\n",
    "\n",
    "ixs = random.choices(range(x_contrast.shape[0]), k=500)\n",
    "\n",
    "plt.scatter(x_contrast[ixs, 0], x_contrast[ixs, 1], c=labels[ixs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X = []\n",
    "labels = []\n",
    "for x, y in test_dataloader:\n",
    "    X.append(x.detach().numpy())\n",
    "    labels.append(y)\n",
    "X = np.concatenate(X).squeeze()\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "print(X.shape)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "print(f\"explained variance: {pca.explained_variance_ratio_}\")\n",
    "print(f\"singular values: {pca.singular_values_}\")\n",
    "\n",
    "labels = np.concatenate(labels)\n",
    "\n",
    "plt.scatter(X_pca[ixs, 0], X_pca[ixs, 1], c=labels[ixs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-sne dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X = []\n",
    "labels = []\n",
    "for x, y in test_dataloader:\n",
    "    X.append(x.detach().numpy())\n",
    "    labels.append(y)\n",
    "X = np.concatenate(X).squeeze()\n",
    "X = X.reshape((X.shape[0], -1))\n",
    "# print(X.shape)\n",
    "\n",
    "X_tsne = TSNE(n_components=2, learning_rate=\"auto\", init=\"random\", perplexity=3).fit_transform(X)\n",
    "X_tsne.shape\n",
    "\n",
    "labels = np.concatenate(labels)\n",
    "plt.scatter(X_tsne[ixs, 0], X_tsne[ixs, 1], c=labels[ixs])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "vars = [\"contrast_1\", \"contrast_2\", \"pca_1\", \"pca_2\", \"tsne_1\", \"tsne_2\"]\n",
    "X = np.concatenate([x_contrast, X_pca, X_tsne], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, stratify=labels, random_state=42)\n",
    "\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "result = permutation_importance(forest, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")\n",
    "forest_importances = pd.Series(result.importances_mean, index=vars)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save embeddings dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from test_nn_template.data.export import EmbeddingsSaver\n",
    "\n",
    "\n",
    "source = os.path.join(NB_PATH, NB_NAME)\n",
    "transform = lambda x: model.model.forward_once(x)\n",
    "class_to_index = {\n",
    "    \"T-shirt/top\": 0,\n",
    "    \"Trouser\": 1,\n",
    "    \"Pullover\": 2,\n",
    "    \"Dress\": 3,\n",
    "    \"Coat\": 4,\n",
    "    \"Sandal\": 5,\n",
    "    \"Shirt\": 6,\n",
    "    \"Sneaker\": 7,\n",
    "    \"Bag\": 8,\n",
    "    \"Ankle boot\": 9,\n",
    "}\n",
    "\n",
    "embeddings_saver = EmbeddingsSaver(run, train_dataloader, test_dataloader, source, class_to_index, transform)\n",
    "embeddings_saver.save(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.load(\"/home/fernando/conversenow/test_nn_template/data/sage-field-17/test/data/embeddings/2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(\"/home/fernando/conversenow/test_nn_template/data/sage-field-17/test/data/labels/2.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-forward classifier trained on embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"fernandoezequiel512/test_nn_template/runs/2841ki1m\"\n",
    "run = WandbHandler.get_run(run_id)\n",
    "print(f\"Got {run.name}\")\n",
    "model = WandbHandler.load_run_model_checkpoint(run_id)\n",
    "print(model)\n",
    "print(f\"Accuract test: {round(run.summary['acc/test'], 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "labels = []\n",
    "for i in np.arange(-1.5, 2, 0.1):\n",
    "    for j in np.arange(-1.5, 2, 0.1):\n",
    "        x.append(i)\n",
    "        y.append(j)\n",
    "        pos = torch.tensor([i, j]).float()\n",
    "        # print(pos.float())\n",
    "        probs = torch.softmax(model(pos), dim=-1)\n",
    "        label = int(probs.argmax().detach())\n",
    "        labels.append(label)\n",
    "\n",
    "plt.scatter(x, y, c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_nn_template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "15811d5068274a7cadd482672f677129ba5c55e94d38dd440bd9a4cbce4a0b06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
